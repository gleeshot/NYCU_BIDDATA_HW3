{"cells":[{"cell_type":"code","execution_count":1,"id":"e946c6e5","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-92d3-m.asia-east1-a.c.direct-branch-347413.internal:42973\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f486d058130>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":2,"id":"4e35a75d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df = spark.read.csv(\"gs://hpl-bucket1/data/yellow_tripdata_2018-10.csv\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":3,"id":"718f23d2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- VendorID: integer (nullable = true)\n"," |-- tpep_pickup_datetime: string (nullable = true)\n"," |-- tpep_dropoff_datetime: string (nullable = true)\n"," |-- passenger_count: integer (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: integer (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: integer (nullable = true)\n"," |-- DOLocationID: integer (nullable = true)\n"," |-- payment_type: integer (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n","\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n","|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n","|       1| 2018-10-01 00:23:34|  2018-10-01 00:44:50|              1|          6.2|         1|                 N|          68|           7|           2|       20.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        21.8|\n","|       1| 2018-10-01 00:40:05|  2018-10-01 01:01:56|              1|         12.6|         1|                 N|         132|           9|           2|       35.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        36.3|\n","|       1| 2018-10-01 00:05:35|  2018-10-01 00:19:38|              1|          6.1|         1|                 N|          50|         244|           1|       19.0|  0.5|    0.5|      5.05|         0.0|                  0.3|       25.35|\n","|       1| 2018-10-01 00:42:56|  2018-10-01 00:49:00|              1|          1.3|         1|                 N|         151|         239|           2|        7.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|\n","|       1| 2018-10-01 00:19:14|  2018-10-01 00:31:54|              1|          2.6|         1|                 N|         233|         143|           1|       11.0|  0.5|    0.5|      2.45|         0.0|                  0.3|       14.75|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.printSchema()\n","df.show(5)"]},{"cell_type":"code","execution_count":4,"id":"0611d00b","metadata":{},"outputs":[],"source":["# select the info we need in q2\n","q2_info = df.select('passenger_count', 'payment_type', 'total_amount')"]},{"cell_type":"code","execution_count":5,"id":"4973b21d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+\n","|passenger_count|payment_type|total_amount|\n","+---------------+------------+------------+\n","|              1|           2|        21.8|\n","|              1|           2|        36.3|\n","|              1|           1|       25.35|\n","|              1|           2|         8.3|\n","|              1|           1|       14.75|\n","+---------------+------------+------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["8821105"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["q2_info.show(5)\n","q2_info.count()"]},{"cell_type":"code","execution_count":6,"id":"3bfd2760","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 7:=======================================>                   (4 + 2) / 6]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+------------------+-------------------+------------------+\n","|summary|   passenger_count|       payment_type|      total_amount|\n","+-------+------------------+-------------------+------------------+\n","|  count|           8821105|            8821105|           8821105|\n","|   mean| 1.569944014950508| 1.3024741231399013| 16.96397637618119|\n","| stddev|1.2188878126211988|0.47957818043819983|136.66237916338224|\n","|    min|                 0|                  1|            -475.3|\n","|    max|                 9|                  5|         403408.18|\n","+-------+------------------+-------------------+------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["q2_info.describe().show()"]},{"cell_type":"code","execution_count":7,"id":"d42c9b54","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["8763628"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# get the cases of the payment type is either credit card or cash\n","target_payment = q2_info.filter((q2_info['payment_type'] > 0) & (q2_info['payment_type'] < 3))\n","target_payment.count()"]},{"cell_type":"code","execution_count":8,"id":"a79fb491","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["8060128"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# get the range of passenge count we need\n","target_passenger = target_payment.filter((q2_info['passenger_count'] > 0) & (q2_info['passenger_count'] < 5))\n","target_passenger.count()"]},{"cell_type":"code","execution_count":9,"id":"d5fe580f","metadata":{},"outputs":[],"source":["import pyspark.sql.functions as F"]},{"cell_type":"code","execution_count":10,"id":"3f995596","metadata":{},"outputs":[],"source":["q2_result = target_passenger.groupBy('passenger_count').agg(F.count('passenger_count'),F.mean('total_amount'),F.max('total_amount'))"]},{"cell_type":"code","execution_count":11,"id":"eae3a45e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 16:======================================>                   (4 + 2) / 6]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+----------------------+------------------+-----------------+\n","|passenger_count|count(passenger_count)| avg(total_amount)|max(total_amount)|\n","+---------------+----------------------+------------------+-----------------+\n","|              1|               6256861|16.850306142476434|        403408.18|\n","|              2|               1276519|17.559149350667102|           2243.7|\n","|              3|                364502| 17.25161049871787|           873.32|\n","|              4|                162246| 17.51855731419773|            490.8|\n","+---------------+----------------------+------------------+-----------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["q2_result.orderBy('passenger_count').show()"]},{"cell_type":"code","execution_count":28,"id":"a7460074","metadata":{},"outputs":[],"source":["txt_file = spark.read.text(\"gs://hpl-bucket1/data/Youvegottofindwhatyoulove.txt\")"]},{"cell_type":"code","execution_count":29,"id":"5861799a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|               value|\n","+--------------------+\n","|I am honored to b...|\n","|                    |\n","|I dropped out of ...|\n","|                    |\n","|It started before...|\n","|                    |\n","|And 17 years late...|\n","|                    |\n","|It wasnâ€™t all rom...|\n","|                    |\n","|Reed College at t...|\n","|                    |\n","|None of this had ...|\n","|                    |\n","|Again, you canâ€™t ...|\n","|                    |\n","|My second story i...|\n","|                    |\n","|I was lucky â€” I f...|\n","|                    |\n","+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["txt_file.show()"]},{"cell_type":"code","execution_count":53,"id":"63038fe2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n","<class 'str'>\n"]}],"source":["rows = txt_file.collect()\n","for i in range(len(rows)):\n","    print(type(rows[i].__getitem__('value')))"]},{"cell_type":"code","execution_count":55,"id":"090bb221","metadata":{},"outputs":[],"source":["# remove punctuation\n","from pyspark.sql.functions import regexp_replace, trim, col, lower"]},{"cell_type":"code","execution_count":56,"id":"a1c68521","metadata":{},"outputs":[],"source":["def removePunctuation(column):\n","    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n","\n","    Note:\n","        Only spaces, letters, and numbers should be retained.  \n","\n","    Args:\n","        column (Column): A Column containing a sentence.\n","\n","    Returns:\n","        Column: A Column named 'sentence' with clean-up operations applied.\n","    \"\"\"\n","    return lower(trim(regexp_replace(column,'\\\\p{Punct}',''))).alias('sentence')"]},{"cell_type":"code","execution_count":57,"id":"3e68582d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|            sentence|\n","+--------------------+\n","|i am honored to b...|\n","|                    |\n","|i dropped out of ...|\n","|                    |\n","|it started before...|\n","+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["txt_df = txt_file.select(removePunctuation(col('value')))\n","txt_df.show(5)"]},{"cell_type":"code","execution_count":58,"id":"774f61e8","metadata":{},"outputs":[],"source":["# words from lines\n","from pyspark.sql.functions import split, explode"]},{"cell_type":"code","execution_count":59,"id":"1827107d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+\n","|   word|\n","+-------+\n","|      i|\n","|     am|\n","|honored|\n","|     to|\n","|     be|\n","+-------+\n","only showing top 5 rows\n","\n"]}],"source":["txt_df = txt_df.select(explode(split(txt_df.sentence, '[\\s]+')).alias('word')).where(\"word!=''\")\n","txt_df.show(5)"]},{"cell_type":"code","execution_count":60,"id":"1ce8da13","metadata":{},"outputs":[],"source":["def wordCount(wordListDF):\n","        \"\"\"Creates a DataFrame with word counts.\n","\n","        Args:\n","            wordListDF (str): A DataFrame consisting of one string column called 'word'.\n","\n","        Returns:\n","            DataFrame of (str, int): A DataFrame containing 'word' and 'count' columns.\n","        \"\"\"\n","        return wordListDF.groupBy('word').count()"]},{"cell_type":"code","execution_count":61,"id":"f0e85437","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----+\n","|   word|count|\n","+-------+-----+\n","|    the|   96|\n","|      i|   86|\n","|     to|   71|\n","|    and|   67|\n","|     it|   53|\n","|    was|   48|\n","|      a|   46|\n","|     of|   41|\n","|   that|   38|\n","|     in|   34|\n","|    you|   31|\n","|     my|   30|\n","|     is|   28|\n","|    had|   22|\n","|    out|   20|\n","|   with|   19|\n","|     me|   18|\n","|   have|   17|\n","|    for|   17|\n","|     so|   17|\n","|   life|   16|\n","|   your|   16|\n","|    all|   16|\n","|     on|   15|\n","|     as|   15|\n","|   what|   15|\n","|college|   14|\n","|     be|   14|\n","|    but|   14|\n","|   from|   13|\n","+-------+-----+\n","only showing top 30 rows\n","\n"]}],"source":["topWordsAndCountsDF = wordCount(txt_df).orderBy(['count'],ascending=False)\n","topWordsAndCountsDF.show(30)"]},{"cell_type":"code","execution_count":null,"id":"d3c33f3d","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}